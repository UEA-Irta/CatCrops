# VARIABLES QUE INTRODUIM AL MODEL

model = "TransformerEncoder" #Select model architecture. Available models are "LSTM","TempCNN","MSRestNet","TransformerEncoder"
trans_type = "default"  # Transform que volem fer a les dades (quines dade seleccionem)
sequencelength = 45  # Rang de dades que fem servir per
datecrop = "26/05/2022"  # Si ho volem tallar a partir d'una data
batchsize = 1024 # number of time series processed simultaneously
epochs = 100 # number of training epochs (training on entire dataset)
mode = "validation" #Training mode. Either "validation" (train on baixter2022 test on lleida2022) or "evaluation" (train on lleida and baixter 2021-2122 test on lleida and baixter 2023)')
datapath = "/media/hdd11/tipus_c/segu/catcrops_dataset/" #Directory to download and store the dataset'
workers = 0 #Number of CPU workers to load the next batch
hyperparameter = dict() #Model specific hyperparameter as single string, separated by comma of format param1=value1,param2=value2
level = "L2A" #Sentinel 2 processing level (L1C, L2A)
weight_decay = 5e-08 #Optimizer weight_decay (default 1e-6)
learning_rate = 1e-3 #Optimizer learning rate (default 1e-2)
preload_ram = True #Load dataset into RAM upon initialization
device = None #torch.Device. either "cpu" or "cuda". Default will check by torch.cuda.is_available()
logdir = "./Results" #Logdir to store progress and models (defaults to /tmp)'
trial = "Trial01"
device = "cpu"